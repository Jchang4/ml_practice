{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('../data/shakespeare/processed.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dict['X']\n",
    "Y = data_dict['Y']\n",
    "dataX = data_dict['dataX']\n",
    "dataY = data_dict['dataY']\n",
    "char_to_idx = data_dict['char_to_idx']\n",
    "idx_to_char = data_dict['idx_to_char']\n",
    "\n",
    "# Constants\n",
    "m, n_timesteps, _ = X.shape\n",
    "_, n_chars = Y.shape\n",
    "n_a = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (13823, 140, 1)\n",
      "Y shape: (13823, 35)\n",
      "Num. Timesteps: 140\n",
      "Num. Unique Chars: 35\n"
     ]
    }
   ],
   "source": [
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('Num. Timesteps:', n_timesteps)\n",
    "print('Num. Unique Chars:', n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_timesteps, n_features, n_a):\n",
    "    x0 = Input(shape=(n_timesteps,1), name='input')\n",
    "    \n",
    "    X = LSTM(n_a, return_sequences=True)(x0)\n",
    "    X = LSTM(n_a)(X)\n",
    "    out = Dense(n_features, activation='softmax')(X)\n",
    "    model = Model(x0, out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(n_timesteps, n_chars, n_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/shakespeare/weights.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "checkpoint_callback = ModelCheckpoint(file_path, \n",
    "                                      monitor='loss',\n",
    "                                      verbose=1, \n",
    "                                      save_best_only=True,\n",
    "                                      mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_initial = np.zeros((n_timesteps, n_a))\n",
    "c_initial = np.zeros((n_timesteps, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.9915\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.99152, saving model to ../data/shakespeare/weights.01-2.99.hdf5\n",
      "Epoch 2/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.9617\n",
      "\n",
      "Epoch 00002: loss improved from 2.99152 to 2.96169, saving model to ../data/shakespeare/weights.02-2.96.hdf5\n",
      "Epoch 3/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.8868\n",
      "\n",
      "Epoch 00003: loss improved from 2.96169 to 2.88677, saving model to ../data/shakespeare/weights.03-2.89.hdf5\n",
      "Epoch 4/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.8250\n",
      "\n",
      "Epoch 00004: loss improved from 2.88677 to 2.82504, saving model to ../data/shakespeare/weights.04-2.83.hdf5\n",
      "Epoch 5/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.7789\n",
      "\n",
      "Epoch 00005: loss improved from 2.82504 to 2.77885, saving model to ../data/shakespeare/weights.05-2.78.hdf5\n",
      "Epoch 6/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.7495\n",
      "\n",
      "Epoch 00006: loss improved from 2.77885 to 2.74945, saving model to ../data/shakespeare/weights.06-2.75.hdf5\n",
      "Epoch 7/20\n",
      " 6784/13823 [=============>................] - ETA: 38s - loss: 2.7372"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, \n",
    "                    epochs=20, \n",
    "                    batch_size=64, \n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Text\n",
    "# Given seed sentence - 140 characters - predict next character\n",
    "# For every predicted char, add to predictions = []\n",
    "\n",
    "def reshape_input(original_input):\n",
    "    return np.reshape(original_input, (1, n_timesteps, 1))\n",
    "\n",
    "def get_p_idx(p):\n",
    "    flattened = np.ndarray.flatten(np.array(p))\n",
    "    return np.random.choice([i for i in range(n_chars)], \n",
    "                            p = flattened)\n",
    "\n",
    "def generate_text(seed_input, model, num_chars_to_generate=140):\n",
    "    if len(seed_input) < 140:\n",
    "        raise Exception('Seed_input must be at least 140 characters')\n",
    "    curr_input = seed_input.lower()\n",
    "    curr_input = list(curr_input)\n",
    "    curr_input = curr_input[:n_timesteps] # first 140 chars\n",
    "    \n",
    "    curr_input = [char_to_idx[c] for c in curr_input]\n",
    "    # Normalize\n",
    "    curr_input = np.array(curr_input) / n_chars\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(num_chars_to_generate):\n",
    "        p = model.predict(reshape_input(curr_input))\n",
    "        p_idx = get_p_idx(p)\n",
    "        predictions.append(idx_to_char[p_idx])\n",
    "        curr_input = np.append(curr_input[1:], p_idx / n_chars)\n",
    "    \n",
    "    return ''.join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_input = \"Haply that name of 'chaste' unhappily set This bateless edge on his keen appetite; When Collatine unwisely did not let To praise the clear unmatched red and white Which triumph'd in that sky of his delight, Where mortal stars, as bright as heaven's beauties, With pure aspects did him peculiar duties.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(seed_input, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
