{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('../data/alice/processed-alice.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dict['X']\n",
    "Y = data_dict['Y']\n",
    "dataX = data_dict['dataX']\n",
    "dataY = data_dict['dataY']\n",
    "char_to_idx = data_dict['char_to_idx']\n",
    "idx_to_char = data_dict['idx_to_char']\n",
    "\n",
    "# Constants\n",
    "m, n_timesteps, _ = X.shape\n",
    "_, n_chars = Y.shape\n",
    "n_a = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (144224, 100, 1)\n",
      "Y shape: (144224, 45)\n",
      "Num. Timesteps: 100\n",
      "Num. Unique Chars: 45\n"
     ]
    }
   ],
   "source": [
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('Num. Timesteps:', n_timesteps)\n",
    "print('Num. Unique Chars:', n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_timesteps, n_features, n_a):\n",
    "    x0 = Input(shape=(n_timesteps,1), name='input')\n",
    "    \n",
    "    X = LSTM(n_a, return_sequences=True)(x0)\n",
    "    X = LSTM(n_a)(X)\n",
    "    out = Dense(n_features, activation='softmax')(X)\n",
    "    model = Model(x0, out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(n_timesteps, n_chars, n_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_initial = np.zeros((n_timesteps, n_a))\n",
    "c_initial = np.zeros((n_timesteps, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "144224/144224 [==============================] - 90s 621us/step - loss: 2.2912\n",
      "Epoch 2/25\n",
      "144224/144224 [==============================] - 84s 581us/step - loss: 2.2690\n",
      "Epoch 3/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.2472\n",
      "Epoch 4/25\n",
      "144224/144224 [==============================] - 82s 571us/step - loss: 2.2311\n",
      "Epoch 5/25\n",
      "144224/144224 [==============================] - 88s 607us/step - loss: 2.2147\n",
      "Epoch 6/25\n",
      "144224/144224 [==============================] - 89s 614us/step - loss: 2.1971\n",
      "Epoch 7/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.1823\n",
      "Epoch 8/25\n",
      "144224/144224 [==============================] - 83s 574us/step - loss: 2.1695\n",
      "Epoch 9/25\n",
      "144224/144224 [==============================] - 83s 572us/step - loss: 2.1553\n",
      "Epoch 10/25\n",
      "144224/144224 [==============================] - 82s 571us/step - loss: 2.1429\n",
      "Epoch 11/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.1316\n",
      "Epoch 12/25\n",
      "144224/144224 [==============================] - 82s 571us/step - loss: 2.1201\n",
      "Epoch 13/25\n",
      "144224/144224 [==============================] - 83s 572us/step - loss: 2.1095\n",
      "Epoch 14/25\n",
      "144224/144224 [==============================] - 82s 571us/step - loss: 2.0984\n",
      "Epoch 15/25\n",
      "144224/144224 [==============================] - 82s 571us/step - loss: 2.0890\n",
      "Epoch 16/25\n",
      "144224/144224 [==============================] - 82s 571us/step - loss: 2.0797\n",
      "Epoch 17/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.0703\n",
      "Epoch 18/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.0621\n",
      "Epoch 19/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.0535\n",
      "Epoch 20/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.0457\n",
      "Epoch 21/25\n",
      "144224/144224 [==============================] - 83s 573us/step - loss: 2.0379\n",
      "Epoch 22/25\n",
      "144224/144224 [==============================] - 83s 574us/step - loss: 2.0305\n",
      "Epoch 23/25\n",
      "144224/144224 [==============================] - 82s 570us/step - loss: 2.0223\n",
      "Epoch 24/25\n",
      "144224/144224 [==============================] - 82s 569us/step - loss: 2.0152\n",
      "Epoch 25/25\n",
      "144224/144224 [==============================] - 82s 571us/step - loss: 2.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f457825e5f8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=25, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 50\n",
    "model.save('../data/trained-{}-epochs.h5'.format(total_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Text\n",
    "# Given seed sentence - 100 characters - predict next character\n",
    "# For every predicted char, add to predictions = []\n",
    "\n",
    "def reshape_input(original_input):\n",
    "    return np.reshape(original_input, (1, n_timesteps, 1))\n",
    "\n",
    "def get_p_idx(p):\n",
    "    flattened = np.ndarray.flatten(np.array(p))\n",
    "    return np.random.choice([i for i in range(n_chars)], \n",
    "                            p = flattened)\n",
    "\n",
    "def generate_text(seed_input, model, num_chars_to_generate=140):\n",
    "    if len(seed_input) < 100:\n",
    "        raise Exception('Seed_input must be at least 100 characters')\n",
    "    curr_input = seed_input.lower()\n",
    "    curr_input = list(curr_input)\n",
    "    curr_input = curr_input[:100] # first 100 chars\n",
    "    \n",
    "    curr_input = [char_to_idx[c] for c in curr_input]\n",
    "    # Normalize\n",
    "    curr_input = np.array(curr_input) / n_chars\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(num_chars_to_generate):\n",
    "        p = model.predict(reshape_input(curr_input))\n",
    "        p_idx = get_p_idx(p)\n",
    "        predictions.append(idx_to_char[p_idx])\n",
    "        curr_input = np.append(curr_input[1:], p_idx / n_chars)\n",
    "    \n",
    "    return ''.join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_input = \"its a race its a race! Lets put it to the test and be our very best. Its a race! Oh my Oh my I must really try to get more characters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar agpi  \\nguesiin to get tellgt would to soto!ouoted.-\\n\\naolwgouse nf thmugdr the huomd\\nhage\\n cos the hard bnitinnsteidn the\\nvrlamd. buthdns '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(seed_input, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
