{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Lambda\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('../data/shakespeare/processed.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dict['X']\n",
    "Y = data_dict['Y']\n",
    "dataX = data_dict['dataX']\n",
    "dataY = data_dict['dataY']\n",
    "char_to_idx = data_dict['char_to_idx']\n",
    "idx_to_char = data_dict['idx_to_char']\n",
    "\n",
    "# Constants\n",
    "m, n_timesteps, _ = X.shape\n",
    "_, n_chars = Y.shape\n",
    "n_a = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (13823, 140, 1)\n",
      "Y shape: (13823, 35)\n",
      "Num. Timesteps: 140\n",
      "Num. Unique Chars: 35\n"
     ]
    }
   ],
   "source": [
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('Num. Timesteps:', n_timesteps)\n",
    "print('Num. Unique Chars:', n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_timesteps, n_features, n_a):\n",
    "    x0 = Input(shape=(n_timesteps,1), name='input')\n",
    "    \n",
    "    X = LSTM(n_a, return_sequences=True)(x0)\n",
    "    X = LSTM(n_a)(X)\n",
    "    out = Dense(n_features, activation='softmax')(X)\n",
    "    model = Model(x0, out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(n_timesteps, n_chars, n_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/shakespeare/weights.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "checkpoint_callback = ModelCheckpoint(file_path, \n",
    "                                      monitor='loss',\n",
    "                                      verbose=1, \n",
    "                                      save_best_only=True,\n",
    "                                      mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_initial = np.zeros((n_timesteps, n_a))\n",
    "c_initial = np.zeros((n_timesteps, n_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.9915\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.99152, saving model to ../data/shakespeare/weights.01-2.99.hdf5\n",
      "Epoch 2/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.9617\n",
      "\n",
      "Epoch 00002: loss improved from 2.99152 to 2.96169, saving model to ../data/shakespeare/weights.02-2.96.hdf5\n",
      "Epoch 3/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.8868\n",
      "\n",
      "Epoch 00003: loss improved from 2.96169 to 2.88677, saving model to ../data/shakespeare/weights.03-2.89.hdf5\n",
      "Epoch 4/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.8250\n",
      "\n",
      "Epoch 00004: loss improved from 2.88677 to 2.82504, saving model to ../data/shakespeare/weights.04-2.83.hdf5\n",
      "Epoch 5/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.7789\n",
      "\n",
      "Epoch 00005: loss improved from 2.82504 to 2.77885, saving model to ../data/shakespeare/weights.05-2.78.hdf5\n",
      "Epoch 6/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.7495\n",
      "\n",
      "Epoch 00006: loss improved from 2.77885 to 2.74945, saving model to ../data/shakespeare/weights.06-2.75.hdf5\n",
      "Epoch 7/20\n",
      "13823/13823 [==============================] - 75s 5ms/step - loss: 2.7272\n",
      "\n",
      "Epoch 00007: loss improved from 2.74945 to 2.72723, saving model to ../data/shakespeare/weights.07-2.73.hdf5\n",
      "Epoch 8/20\n",
      "13823/13823 [==============================] - 71s 5ms/step - loss: 2.7075\n",
      "\n",
      "Epoch 00008: loss improved from 2.72723 to 2.70752, saving model to ../data/shakespeare/weights.08-2.71.hdf5\n",
      "Epoch 9/20\n",
      "13823/13823 [==============================] - 71s 5ms/step - loss: 2.6876\n",
      "\n",
      "Epoch 00009: loss improved from 2.70752 to 2.68756, saving model to ../data/shakespeare/weights.09-2.69.hdf5\n",
      "Epoch 10/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.6682\n",
      "\n",
      "Epoch 00010: loss improved from 2.68756 to 2.66820, saving model to ../data/shakespeare/weights.10-2.67.hdf5\n",
      "Epoch 11/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.6503\n",
      "\n",
      "Epoch 00011: loss improved from 2.66820 to 2.65025, saving model to ../data/shakespeare/weights.11-2.65.hdf5\n",
      "Epoch 12/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.6309\n",
      "\n",
      "Epoch 00012: loss improved from 2.65025 to 2.63089, saving model to ../data/shakespeare/weights.12-2.63.hdf5\n",
      "Epoch 13/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.6096\n",
      "\n",
      "Epoch 00013: loss improved from 2.63089 to 2.60958, saving model to ../data/shakespeare/weights.13-2.61.hdf5\n",
      "Epoch 14/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.5882\n",
      "\n",
      "Epoch 00014: loss improved from 2.60958 to 2.58823, saving model to ../data/shakespeare/weights.14-2.59.hdf5\n",
      "Epoch 15/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.5653\n",
      "\n",
      "Epoch 00015: loss improved from 2.58823 to 2.56534, saving model to ../data/shakespeare/weights.15-2.57.hdf5\n",
      "Epoch 16/20\n",
      "13823/13823 [==============================] - 73s 5ms/step - loss: 2.5394\n",
      "\n",
      "Epoch 00016: loss improved from 2.56534 to 2.53943, saving model to ../data/shakespeare/weights.16-2.54.hdf5\n",
      "Epoch 17/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.5161\n",
      "\n",
      "Epoch 00017: loss improved from 2.53943 to 2.51609, saving model to ../data/shakespeare/weights.17-2.52.hdf5\n",
      "Epoch 18/20\n",
      "13823/13823 [==============================] - 71s 5ms/step - loss: 2.4872\n",
      "\n",
      "Epoch 00018: loss improved from 2.51609 to 2.48723, saving model to ../data/shakespeare/weights.18-2.49.hdf5\n",
      "Epoch 19/20\n",
      "13823/13823 [==============================] - 72s 5ms/step - loss: 2.4578\n",
      "\n",
      "Epoch 00019: loss improved from 2.48723 to 2.45784, saving model to ../data/shakespeare/weights.19-2.46.hdf5\n",
      "Epoch 20/20\n",
      "13823/13823 [==============================] - 74s 5ms/step - loss: 2.4230\n",
      "\n",
      "Epoch 00020: loss improved from 2.45784 to 2.42300, saving model to ../data/shakespeare/weights.20-2.42.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, \n",
    "                    epochs=20, \n",
    "                    batch_size=64, \n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Text\n",
    "# Given seed sentence - 140 characters - predict next character\n",
    "# For every predicted char, add to predictions = []\n",
    "\n",
    "def reshape_input(original_input):\n",
    "    return np.reshape(original_input, (1, n_timesteps, 1))\n",
    "\n",
    "def get_p_idx(p):\n",
    "    flattened = np.ndarray.flatten(np.array(p))\n",
    "    return np.random.choice([i for i in range(n_chars)], \n",
    "                            p = flattened)\n",
    "\n",
    "def generate_text(seed_input, model, num_chars_to_generate=140):\n",
    "    if len(seed_input) < 140:\n",
    "        raise Exception('Seed_input must be at least 140 characters')\n",
    "    curr_input = seed_input.lower()\n",
    "    curr_input = list(curr_input)\n",
    "    curr_input = curr_input[:n_timesteps] # first 140 chars\n",
    "    \n",
    "    curr_input = [char_to_idx[c] for c in curr_input]\n",
    "    # Normalize\n",
    "    curr_input = np.array(curr_input) / n_chars\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(num_chars_to_generate):\n",
    "        p = model.predict(reshape_input(curr_input))\n",
    "        p_idx = get_p_idx(p)\n",
    "        predictions.append(idx_to_char[p_idx])\n",
    "        curr_input = np.append(curr_input[1:], p_idx / n_chars)\n",
    "    \n",
    "    return ''.join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_input = \"Haply that name of 'chaste' unhappily set This bateless edge on his keen appetite; When Collatine unwisely did not let To praise the clear unmatched red and white Which triumph'd in that sky of his delight, Where mortal stars, as bright as heaven's beauties, With pure aspects did him peculiar duties.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(seed_input, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
