{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Style Transfer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dependencies\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras.preprocessing.image import load_img, img_to_array, save_img\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Config Variables / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. Content Layers: 1\n",
      "Num. Style Layers:   5\n"
     ]
    }
   ],
   "source": [
    "# Config Variables / Constants\n",
    "\n",
    "# Images\n",
    "TARGET_HEIGHT = 512\n",
    "TARGET_WIDTH = 512\n",
    "TARGET_CHANNELS = 3\n",
    "\n",
    "# Image Paths\n",
    "CONTENT_PATH = '../data/turtle.png'\n",
    "STYLE_PATH = '../data/van-gogh.jpg'\n",
    "\n",
    "# VGG 19 Layers\n",
    "CONTENT_LAYERS = ['block5_conv2']\n",
    "STYLE_LAYERS = [('block1_conv1', 0.2),\n",
    "                ('block2_conv1', 0.2),\n",
    "                ('block3_conv1', 0.2),\n",
    "                ('block4_conv1', 0.2),\n",
    "                ('block5_conv1', 0.2)]\n",
    "\n",
    "print('Num. Content Layers:', len(CONTENT_LAYERS))\n",
    "print('Num. Style Layers:  ', len(STYLE_LAYERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Helper Functions\n",
    "def show_img(image, title=''):\n",
    "    plt.imshow(image)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def vgg19_preprocess_img(img):\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def preprocess_img(path_to_img, show = False, title = ''):\n",
    "    img = load_img(path_to_img, target_size=(TARGET_HEIGHT, TARGET_WIDTH))\n",
    "    if show:\n",
    "        show_img(img, title)\n",
    "    img = img_to_array(img)\n",
    "    return vgg19_preprocess_img(img)\n",
    "\n",
    "def deprocess_img(img):\n",
    "    x = img.copy()\n",
    "    \n",
    "    if len(x.shape) == 4:\n",
    "        x = np.squeeze(x, 0)\n",
    "    assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
    "                             \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
    "    if len(x.shape) != 3:\n",
    "        raise ValueError(\"Invalid input to deprocess_img()\")\n",
    "    \n",
    "    # Inverse of preprocessing\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    \n",
    "    # Ensure we're in the range of (0, 255)\n",
    "    x = np.clip(x, 0., 255.).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def generate_noise_image(content_image, noise_ratio = 0.6):\n",
    "    \"\"\"\n",
    "    Generates a noisy image by adding random noise to the content_image\n",
    "    \"\"\"\n",
    "    # Generate a random noise_image\n",
    "    noise_image = np.random.uniform(-20, 20, (TARGET_HEIGHT, TARGET_WIDTH, TARGET_CHANNELS)).astype('float32')\n",
    "    \n",
    "    # Set the input_image to be a weighted average of the content_image and a noise_image\n",
    "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
    "    \n",
    "    return vgg19_preprocess_img(input_image)\n",
    "\n",
    "def generate_img(content_image, noise_ratio = 0.6, show = False):\n",
    "\"\"\"\n",
    "    Generates a noisy image by adding random noise to the content_image\n",
    "    \"\"\"\n",
    "    # Generate a random noise_image\n",
    "    img = np.random.uniform(-20, 20, (TARGET_HEIGHT, TARGET_WIDTH, TARGET_CHANNELS)).astype('float32')    \n",
    "    # Set the input_image to be a weighted average of the content_image and a noise_image\n",
    "    img = img * noise_ratio + content_image * (1 - noise_ratio)\n",
    "\n",
    "    if show:\n",
    "        show_img(img, 'Generated Image')\n",
    "        \n",
    "    return vgg19_preprocess_img(img)\n",
    "\n",
    "def save_image(path_to_save, img):\n",
    "    img = deprocess_img(img)\n",
    "    save_img(path_to_save, img, file_format=\"jpg\")\n",
    "    print('Saved image!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Helper Functions\n",
    "def mean_squared_error(a, b):\n",
    "    return tf.reduce_mean(tf.square(a - b))\n",
    "\n",
    "def gram_matrix(a):\n",
    "    return tf.matmul(a, tf.transpose(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Helper Functions\n",
    "def get_model():\n",
    "    \"\"\" Load VGG19 model with the appropriate outputs \"\"\"\n",
    "    model = vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    model.trainable = False\n",
    "    \n",
    "    content_output = [model.get_layer(layer_name).output for layer_name in CONTENT_LAYERS]\n",
    "    style_output = [model.get_layer(layer_name).output for layer_name,coeff in STYLE_LAYERS]\n",
    "    model_outputs = content_output + style_output\n",
    "    \n",
    "    return Model(inputs=model.inputs, outputs=model_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Content, Style, and Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Shape:   (1, 512, 512, 3)\n",
      "Style Shape:     (1, 512, 512, 3)\n",
      "Generated Shape: (1, 512, 512, 3)\n",
      "Tensor(\"model_1/block5_conv2/Relu:0\", shape=(1, 32, 32, 512), dtype=float32)\n",
      "Tensor(\"model_1/block1_conv1/Relu:0\", shape=(1, 512, 512, 64), dtype=float32)\n",
      "Tensor(\"model_1/block2_conv1/Relu:0\", shape=(1, 256, 256, 128), dtype=float32)\n",
      "Tensor(\"model_1/block3_conv1/Relu:0\", shape=(1, 128, 128, 256), dtype=float32)\n",
      "Tensor(\"model_1/block4_conv1/Relu:0\", shape=(1, 64, 64, 512), dtype=float32)\n",
      "Tensor(\"model_1/block5_conv1/Relu:0\", shape=(1, 32, 32, 512), dtype=float32)\n",
      "(1, 32, 32, 512)\n",
      "(1, 512, 512, 64)\n",
      "(1, 256, 256, 128)\n",
      "(1, 128, 128, 256)\n",
      "(1, 64, 64, 512)\n",
      "(1, 32, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "# Load Content, Style, and Generated Images\n",
    "content_img = preprocess_img(CONTENT_PATH, show=True, title='Content Image')\n",
    "style_img = preprocess_img(STYLE_PATH, show=True, title='Style Image')\n",
    "generated_img = generate_img(show=True)\n",
    "\n",
    "print('Content Shape:  ', content_img.shape)\n",
    "print('Style Shape:    ', style_img.shape)\n",
    "print('Generated Shape:', generated_img.shape)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x = tf.Variable(content_img)\n",
    "    model = get_model()\n",
    "    out = model(x)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in out:\n",
    "        print(i)\n",
    "    for i in sess.run(out):\n",
    "        print(i.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_content = 6.7655926\n",
      "Should be = 6.76559\n"
     ]
    }
   ],
   "source": [
    "def compute_content_cost(a_C, a_G):\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_C = tf.reshape(a_C, [n_C, n_H * n_W])\n",
    "    a_G = tf.reshape(a_G, [n_C, n_H * n_W])\n",
    "    \n",
    "    constant = 1/(4 * n_H * n_W * n_C)\n",
    "    return constant * tf.reduce_sum(tf.square(a_C - a_G))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    a_C = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "    J_content = compute_content_cost(a_C, a_G)\n",
    "    print(\"J_content = \" + str(J_content.eval()))\n",
    "    \n",
    "    print(\"Should be =\", str(6.76559))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_style_layer = 9.190277\n",
      "Should be     = 9.19028\n"
     ]
    }
   ],
   "source": [
    "def compute_style_cost_one_layer(a_S, a_G):\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    \n",
    "    a_S = tf.reshape(tf.transpose(a_S), [n_C, n_H * n_W])\n",
    "    a_G = tf.reshape(tf.transpose(a_G), [n_C, n_H * n_W])\n",
    "        \n",
    "    gram_S = gram_matrix(a_S)\n",
    "    gram_G = gram_matrix(a_G)\n",
    "    \n",
    "    constant = 1/(4 * n_C**2 * (n_H * n_W)**2)\n",
    "    return constant * tf.reduce_sum(tf.square(gram_S - gram_G))\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    a_S = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "    a_G = tf.random_normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "    J_style_layer = compute_style_cost_one_layer(a_S, a_G)\n",
    "    \n",
    "    print(\"J_style_layer = \" + str(J_style_layer.eval()))\n",
    "    print(\"Should be     =\", str(9.19028))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost(style_activations, generated_activations):\n",
    "    J_style = 0\n",
    "    for i,(layer_name, coeff) in enumerate(STYLE_LAYERS):\n",
    "        a_S = style_activations[i]\n",
    "        a_G = generated_activations[i]\n",
    "        J_curr = compute_style_cost_one_layer(a_S, a_G)\n",
    "        J_style += coeff * J_curr\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J         = 35.34667875478276\n",
      "Should be = 35.34667875478276\n"
     ]
    }
   ],
   "source": [
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    return alpha * J_content + beta * J_style\n",
    "\n",
    "def compute_grads(loss, image):\n",
    "    return K.gradients(loss, image)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as test:\n",
    "    np.random.seed(3)\n",
    "    J_content = np.random.randn()    \n",
    "    J_style = np.random.randn()\n",
    "    J = total_cost(J_content, J_style)\n",
    "    print(\"J         = \" + str(J))\n",
    "    print(\"Should be =\", str(35.34667875478276))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving the optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Images (again)\n",
    "content_img = tf.constant(preprocess_img(CONTENT_PATH, show=False, title='Content Image'), name='content_img', dtype=tf.float32)\n",
    "style_img = tf.constant(preprocess_img(STYLE_PATH, show=False, title='Style Image'), name='style_img', dtype=tf.float32)\n",
    "generated_img = tf.Variable(generate_img(show=False), name='generated_img', dtype=tf.float32)\n",
    "\n",
    "# Get the model\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(sess, input_image, num_iterations = 200):    \n",
    "    generated_img = input_image\n",
    "    a_C = model(content_img)[0]\n",
    "    a_S = model(style_img)[1:]\n",
    "    a_G = model(generated_img)\n",
    "    \n",
    "    J_content = compute_content_cost(a_C, a_G[0])\n",
    "    J_style = compute_style_cost(a_S, a_G[1:])\n",
    "    J = total_cost(J_content, J_style)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(2.0)\n",
    "    grads = compute_grads(J, generated_img)[0]\n",
    "    train_step = optimizer.apply_gradients([(grads, generated_img)])\n",
    "    \n",
    "    norm_means = np.array([103.939, 116.779, 123.68])\n",
    "    min_vals = -norm_means\n",
    "    max_vals = 255 - norm_means\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(num_iterations):        \n",
    "        sess.run(train_step)\n",
    "        \n",
    "        clipped = tf.clip_by_value(generated_img, min_vals, max_vals)\n",
    "        generated_img.assign(clipped)\n",
    "        \n",
    "        # Print every 20 iteration.\n",
    "        if i % 20 == 0:\n",
    "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js) + '\\n')\n",
    "            save_img('../images/nst-{}.jpg'.format(i), sess.run(clipped)[0])\n",
    "    \n",
    "    save_img('../images/nst-final.jpg', generated_img[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "total cost = 109437.04\n",
      "content cost = 0.014787436\n",
      "style cost = 2735.9224\n",
      "\n",
      "Iteration 20 :\n",
      "total cost = 19430.08\n",
      "content cost = 0.0052772295\n",
      "style cost = 485.7507\n",
      "\n",
      "Iteration 40 :\n",
      "total cost = 6104.4243\n",
      "content cost = 0.0021219426\n",
      "style cost = 152.61008\n",
      "\n",
      "Iteration 60 :\n",
      "total cost = 3767.1562\n",
      "content cost = 0.0012440593\n",
      "style cost = 94.1786\n",
      "\n",
      "Iteration 80 :\n",
      "total cost = 2730.4592\n",
      "content cost = 0.00095455506\n",
      "style cost = 68.261246\n",
      "\n",
      "Iteration 100 :\n",
      "total cost = 2048.04\n",
      "content cost = 0.0007946841\n",
      "style cost = 51.2008\n",
      "\n",
      "Iteration 120 :\n",
      "total cost = 1585.1931\n",
      "content cost = 0.00066086324\n",
      "style cost = 39.62966\n",
      "\n",
      "Iteration 140 :\n",
      "total cost = 1268.6584\n",
      "content cost = 0.0005569083\n",
      "style cost = 31.716322\n",
      "\n",
      "Iteration 160 :\n",
      "total cost = 1049.8046\n",
      "content cost = 0.0004850097\n",
      "style cost = 26.244993\n",
      "\n",
      "Iteration 180 :\n",
      "total cost = 892.59503\n",
      "content cost = 0.00043995774\n",
      "style cost = 22.314766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_nn(sess, generated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
